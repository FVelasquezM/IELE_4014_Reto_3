{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IELE_4014**  \n",
    "**Felipe Velásquez Montoya**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; *cód estudiante:* 201632422\n",
    "# Reto 3\n",
    "Problema de clasificación de Pulsares utilizando el dataset HTRU2 (https://archive.ics.uci.edu/ml/datasets/HTRU2) y una regresión logística de desarrollo propio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paso 0** Instalanción de librería numpy para facilitar operaciones con matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importación de dependencias random, math y numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se importa numpy para facilitar las operaciones con matrices\n",
    "import random\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desarrollo de la regresión logística\n",
    "\n",
    "Se muestra, a continuación, el código de la regresión logística y sus respectivas funciones auxiliares. se inicia con la función train_test_split, diseñada para imitar el comportamiento de su homónima en sklearn. \n",
    "\n",
    "Este método divide un conjunto de datos en datos de entrenamiento y datos de prueba. Lo anterior se hace de manera aleatoria, por lo que no hay garantía alguna de que los conjuntos resultantes tengan la misma distribución de probabilidad.\n",
    "\n",
    "La metodología utilizada consiste en recorrer las listas y generar un número al azar por cada elemento, si número generado es menor o igual a la rata dada por el tamaño del conjunto de entrenamiento dividido entre el tamaño total del conjunto, se añade al conjunto de entrenamiento. De modo contrario, se añade al conjunto de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Método auxiliar que divide los datos entre entranamiento y test\n",
    "#test_ratio es el porcentaje total de los datos que se usará para test.\n",
    "#Hace la división al azar utilizando random.random\n",
    "#Pre: X_set  y y_set deben tener el mismo orden, es decir, para todo elemento X_i \n",
    "# de la X_set, y_i en el conjunto y_set debe ser su respectiva pareja.\n",
    "def train_test_split(X_set, y_set, test_ratio):\n",
    "    \n",
    "    test_size = math.floor(test_ratio*len(X_set))\n",
    "    current_test_size = 0\n",
    "        \n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    \n",
    "    for i in range(len(X_set)):\n",
    "        \n",
    "        if random.random() <= test_ratio and current_test_size < test_size:\n",
    "            X_test.append(X_set[i])\n",
    "            y_test.append(y_set[i])\n",
    "            current_test_size += 1\n",
    "        else:\n",
    "            X_train.append(X_set[i])\n",
    "            y_train.append(y_set[i])\n",
    "    \n",
    "    #En caso de que test no quede del tamaño requerido, se sacan los últimos elementos de train\n",
    "    while len(X_test) != test_size:\n",
    "        X_test.append(X_train.pop())\n",
    "        y_test.append(y_train.pop())\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se presenta, a continuación, la clase LogisticRegression. Esta contiene la función *fit* que utiliza un descenso de gradiente estocástico para entrenar el modelo. Las funciones *sigmoid* y *predict* sirven de funciones auxiliares y *accuracy* y *confusion_matrix* sirven para evaluar el modelo desarrollado.\n",
    "\n",
    "*accuracy* da el número de aciertos (TP+TN) dividido entre el total de elementos. <br>\n",
    "*confusion_matrix* calcula los elementos de la matriz de confusión del modelo, es decir, verdaderos positivos (TP), falsos positivos (FP), verdaderos negativos (TN) y falsos negativos (FN). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, sensitivity = 0.7, suppress_output = False):\n",
    "        self.W = None\n",
    "        self.sensitivity = sensitivity\n",
    "        self.suppress_output = suppress_output\n",
    "        \n",
    "    #Descenso estocástico de gradiente para regresión lineal.\n",
    "    #training_data_X es una matriz que representa el conjunto de x_i's\n",
    "    #training_data_y es una matriz que representa el conjunto de y_i's. Esta matriz tiene únicamente una \n",
    "    #Pre: training_data_X  y training_data_y deben tener el mismo orden, es decir, para todo elemento X_i \n",
    "    # de la matriz training_data_X, y_i en el conjunto training_data_y debe ser su respectiva pareja.\n",
    "    # ejemplo, la fila 0 de training_data_X tiene como respectivo valor y el que está dado por \n",
    "    # la fila 0 de training_data_y\n",
    "    #Pre: training_data_y es 0 o 1.\n",
    "    def fit(self, training_data_X, training_data_y,learning_rate= 0.001, max_iterations = 10000):\n",
    "        \n",
    "        #Para evitar que la embarre y ponga un learning rate demasiado alto que lleve a que el método no converja \n",
    "        if learning_rate > 0.0001:\n",
    "            learning_rate = 0.0001\n",
    "    \n",
    "        #Se inicializa W en ceros, de dimensión (columnas X, 1).\n",
    "        #Se hace así para que no se tenga que transponer W.\n",
    "        W = np.zeros(shape = (1, len(training_data_X[0])))\n",
    "    \n",
    "        iterations = 0\n",
    "        no_improv_it = 0\n",
    "        last_error = 0\n",
    "        new_error = 0\n",
    "    \n",
    "        #Se estimará el gradiente a partir, únicamente, de uno de los datos\n",
    "        while iterations < max_iterations and no_improv_it < 100 :\n",
    "        \n",
    "            #Seleccionar un dato al azar.\n",
    "            i = math.floor(random.random()*len(training_data_X))\n",
    "    \n",
    "            #Calcular error del dato seleccionado al azar.sigmoid(np.dot(training_data_X[i], W.transpose())[0])\n",
    "            e = self.predict(W, training_data_X[i]) - training_data_y[i]\n",
    "            #Estimar gradiente con el error anterior\n",
    "            estimated_grad = np.multiply(e, training_data_X[i])\n",
    "        \n",
    "            W = W - np.multiply(learning_rate, estimated_grad)\n",
    "            \n",
    "            #Si no hubo una mejora en el error cuadrático, reducir tasa de aprendizaje (puede que se esté \"saltando\" el punto óptimo)\n",
    "            if last_error < e:\n",
    "                learning_rate*=0.9\n",
    "                no_improv_it = 0\n",
    "            elif last_error == e:\n",
    "                no_improv_it += 1\n",
    "            else:\n",
    "                no_improv_it = 0\n",
    "        \n",
    "            last_error = e\n",
    "            iterations += 1        \n",
    "        \n",
    "        self.W = W\n",
    "        \n",
    "        if not self.suppress_output:\n",
    "            print(\"----------------------------------------------\")\n",
    "            print(\"SDG finished, finishing error %s\" % last_error)\n",
    "            print(\"W found: %s\" % W)\n",
    "            print(\" Score found for the model with training data: %s\" % self.accuracy(training_data_X, training_data_y))\n",
    "           \n",
    "\n",
    "        \n",
    "    #Calcula el error.\n",
    "    def accuracy(self, test_data_X, test_data_y):\n",
    "    \n",
    "        correct = 0\n",
    "        incorrect = 0\n",
    "        \n",
    "        for i in range(0, len(test_data_X)):\n",
    "        \n",
    "            #si se predice 1 pero es 0\n",
    "            if  self.predict(self.W, test_data_X[i]) >= self.sensitivity and test_data_y[i] == 0:\n",
    "                incorrect += 1\n",
    "            #si se predice 1 y es 1\n",
    "            elif self.predict(self.W, test_data_X[i]) >= self.sensitivity and test_data_y[i] == 1:\n",
    "                correct+=1\n",
    "            #si se predice 0 y es 1\n",
    "            elif self.predict(self.W, test_data_X[i]) < self.sensitivity and test_data_y[i] == 1:\n",
    "                incorrect+=1\n",
    "            #si se predice 0 y es 0\n",
    "            else:\n",
    "                correct+=1\n",
    "    \n",
    "        return correct/(correct+incorrect)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1+math.exp(-x))\n",
    "\n",
    "    def predict(self, W, X_i):\n",
    "        return self.sigmoid(np.dot(X_i, W.transpose())[0])\n",
    "    \n",
    "    def confusion_matrix(self, test_data_X, test_data_y):\n",
    "        \n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        tn = 0\n",
    "        fn = 0\n",
    "        \n",
    "        for i in range(0, len(test_data_X)):\n",
    "            \n",
    "            #si se predice 1 pero es 0\n",
    "            if  self.predict(self.W, test_data_X[i]) >= self.sensitivity and test_data_y[i] == 0:\n",
    "                fp += 1\n",
    "            #si se predice 1 y es 1\n",
    "            elif self.predict(self.W, test_data_X[i]) >= self.sensitivity and test_data_y[i] == 1:\n",
    "                tp += 1\n",
    "            #si se predice 0 y es 1\n",
    "            elif self.predict(self.W, test_data_X[i]) < self.sensitivity and test_data_y[i] == 1:\n",
    "                fn += 1\n",
    "            #si se predice 0 y es 0\n",
    "            else:\n",
    "                tn += 1\n",
    "                \n",
    "        return tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solución del problema de clasificación de pulsares\n",
    "Ya expuesta la regresión logística que se desarrolló, se probará la misma atacando el problema de clasificación de pulsares.\n",
    "\n",
    "Se inicia con la carga de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas de la matriz: 17898\n",
      "Columnas de la matriz: 9\n"
     ]
    }
   ],
   "source": [
    "data_matrix = np.loadtxt(open(\"./HTRU2/HTRU_2.csv\", \"rb\"), delimiter=\",\", skiprows=0)\n",
    "\n",
    "print(\"Filas de la matriz: \" + str(len(data_matrix)))\n",
    "print(\"Columnas de la matriz: \" + str(len(data_matrix[0])))\n",
    "\n",
    "X = np.resize(data_matrix, (len(data_matrix), len(data_matrix[0])-1))\n",
    "y = data_matrix[:,len(data_matrix[0])-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se usa el método *train_test_split* desarrollado para dividir los datos en dos conjuntos, datos de prueba con 10000 elementos y datos de entrenamiento, con los 7898 restantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size: 7898\n",
      "y_train size: 7898\n",
      "X_test size: 10000\n",
      "y_test size: 10000\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_ratio = 10000.00/float(len(X))) \n",
    "\n",
    "print(\"X_train size: %s\" %len(X_train))\n",
    "print(\"y_train size: %s\" %len(y_train)) \n",
    "print(\"X_test size: %s\" %len(X_test)) \n",
    "print(\"y_test size: %s\" %len(y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se vuelve a utilizar el método *train_test_split*, esta vez para dividir los datos de entrenamiento en conjuntos de 100, 500, 1000 y 5000 datos. Como se puede comprobar por la información impresa en consola, son creados cuatro nuevos conjuntos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "Set de entrenamiento 0\n",
      "    Tamaño X de entrenamiento: 100 | Tamaño y de entrenamiento: 100\n",
      "-----------------------------\n",
      "Set de entrenamiento 1\n",
      "    Tamaño X de entrenamiento: 500 | Tamaño y de entrenamiento: 500\n",
      "-----------------------------\n",
      "Set de entrenamiento 2\n",
      "    Tamaño X de entrenamiento: 1000 | Tamaño y de entrenamiento: 1000\n",
      "-----------------------------\n",
      "Set de entrenamiento 3\n",
      "    Tamaño X de entrenamiento: 5000 | Tamaño y de entrenamiento: 5000\n"
     ]
    }
   ],
   "source": [
    "sizes = [100.00, 500.00, 1000.00, 5000.00]\n",
    "X_train_array = []\n",
    "y_train_array = []\n",
    "\n",
    "for i in sizes:\n",
    "    Xy = train_test_split(X_train, y_train, test_ratio = 1.00 - i/float(len(X_train)))\n",
    "    X_train_array.append(Xy[0])\n",
    "    y_train_array.append(Xy[2])\n",
    "    \n",
    "#Verificar tamaños de los nuevos sets de entrenamiento\n",
    "for i in range(0, len(X_train_array)):\n",
    "    print(\"-----------------------------\")\n",
    "    print(\"Set de entrenamiento %s\" % i)\n",
    "    print(\"    Tamaño X de entrenamiento: %s | Tamaño y de entrenamiento: %s\" \n",
    "          % (len(X_train_array[i]), len(y_train_array[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se evaluan los modelos con los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "El Modelo entrenado con 100.0 datos predijo correctamente el 0.9084 porciento de los datos de entrenamiento\n",
      "Matriz de confusión encontrada (TP, FP, TN, FN): (0, 0, 9084, 916)\n",
      "------------------------------------------------------------------------\n",
      "El Modelo entrenado con 500.0 datos predijo correctamente el 0.9084 porciento de los datos de entrenamiento\n",
      "Matriz de confusión encontrada (TP, FP, TN, FN): (0, 0, 9084, 916)\n",
      "------------------------------------------------------------------------\n",
      "El Modelo entrenado con 1000.0 datos predijo correctamente el 0.9084 porciento de los datos de entrenamiento\n",
      "Matriz de confusión encontrada (TP, FP, TN, FN): (0, 0, 9084, 916)\n",
      "------------------------------------------------------------------------\n",
      "El Modelo entrenado con 5000.0 datos predijo correctamente el 0.9084 porciento de los datos de entrenamiento\n",
      "Matriz de confusión encontrada (TP, FP, TN, FN): (0, 0, 9084, 916)\n"
     ]
    }
   ],
   "source": [
    "logreg_array = []\n",
    "logreg_score = []\n",
    "\n",
    "for i in range(0, len(X_train_array)):\n",
    "    \n",
    "    lg = LogisticRegression(suppress_output = True)\n",
    "    \n",
    "    #Se entrena la regresión logística con el conjunto de entrenamiento correspondiente.\n",
    "    logreg_array.append(lg)\n",
    "    lg.fit(X_train_array[i], y_train_array[i])\n",
    "    \n",
    "    #Se prueba la regresión logística con los conjuntos de prueba:\n",
    "    logreg_score.append(logreg_array[i].accuracy(X_test, y_test))\n",
    "    \n",
    "    #Se imprimen los resultados del modelo\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    print(\"El Modelo entrenado con %s datos predijo correctamente el %s porciento de los datos de entrenamiento\" \n",
    "         % (sizes[i], logreg_score[i]))\n",
    "    print(\"Matriz de confusión encontrada (TP, FP, TN, FN): %s\" % str(lg.confusion_matrix(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obsérvese que al igual que en el reto 1, la regresión logística predice que todos los datos hacen parte de la clase mayoritaria. Por esto mismo, se observa que la exactitud del modelo es igual al porcentaje de datos pertenecientes a la clase mayoritaria (0).\n",
    "\n",
    "En este caso, sin embargo, es posible ajustar la *sensibilidad* (porcentaje de seguridad a partir del cual se dice que el dato pertenece a la clase 1). En la regresión implementada, toma un valor por defecto de 0.7, sin embargo, si se reduce a 0.3 podrá verse que, a pesar de que la exactitud de los modelos se reduce, esta vez clasifican a algunos objetos (así sea erróneamente) como pertenecientes a la clase 1. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "El Modelo entrenado con 100.0 datos predijo correctamente el 0.8642 porciento de los datos de entrenamiento\n",
      "Matriz de confusión encontrada (TP, FP, TN, FN): (50, 492, 8592, 866)\n",
      "------------------------------------------------------------------------\n",
      "El Modelo entrenado con 500.0 datos predijo correctamente el 0.8009 porciento de los datos de entrenamiento\n",
      "Matriz de confusión encontrada (TP, FP, TN, FN): (128, 1203, 7881, 788)\n",
      "------------------------------------------------------------------------\n",
      "El Modelo entrenado con 1000.0 datos predijo correctamente el 0.8873 porciento de los datos de entrenamiento\n",
      "Matriz de confusión encontrada (TP, FP, TN, FN): (18, 229, 8855, 898)\n",
      "------------------------------------------------------------------------\n",
      "El Modelo entrenado con 5000.0 datos predijo correctamente el 0.7845 porciento de los datos de entrenamiento\n",
      "Matriz de confusión encontrada (TP, FP, TN, FN): (136, 1375, 7709, 780)\n"
     ]
    }
   ],
   "source": [
    "logreg_array = []\n",
    "logreg_score = []\n",
    "\n",
    "for i in range(0, len(X_train_array)):\n",
    "    \n",
    "    lg = LogisticRegression(suppress_output = True, sensitivity = 0.3)\n",
    "    \n",
    "    #Se entrena la regresión logística con el conjunto de entrenamiento correspondiente.\n",
    "    logreg_array.append(lg)\n",
    "    lg.fit(X_train_array[i], y_train_array[i])\n",
    "    \n",
    "    #Se prueba la regresión logística con los conjuntos de prueba:\n",
    "    logreg_score.append(logreg_array[i].accuracy(X_test, y_test))\n",
    "    \n",
    "    #Se imprimen los resultados del modelo\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    print(\"El Modelo entrenado con %s datos predijo correctamente el %s porciento de los datos de entrenamiento\" \n",
    "         % (sizes[i], logreg_score[i]))\n",
    "    print(\"Matriz de confusión encontrada (TP, FP, TN, FN): %s\" % str(lg.confusion_matrix(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede observarse, la exactitud del modelo se no se ve mayormente afectada y, ahora, algunos de los datos se predicen como pertenecientes a la clase 1. Sin embargo, debe resaltarse que aún hay un gran número de falsos negativos. Por lo tanto, si lo que se buscara hacer con este modelo fuera un programa que ayudara a los científicos a \"marcar\" los objetos candidatos a ser pulsares, este no sería adecuado, pues no marcaría a la mayoría de lo objetos correspondientes a pulsares. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
